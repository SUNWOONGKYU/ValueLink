# íˆ¬ì ë‰´ìŠ¤ ìŠ¤í¬ë˜í•‘ ë° ë­í‚¹ ì‹œìŠ¤í…œ

**êµ­ë‚´ 19ê°œ íˆ¬ììœ ì¹˜ ë‰´ìŠ¤ ì‚¬ì´íŠ¸ì˜ ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ë­í‚¹ ì‹œìŠ¤í…œ**

---

## ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”

- **ëª©ì **: 2026ë…„ 1ì›” 1ì¼ ~ í˜„ì¬ê¹Œì§€ íˆ¬ììœ ì¹˜ ê´€ë ¨ ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ì‚¬ì´íŠ¸ë³„ ë­í‚¹
- **ëŒ€ìƒ**: 19ê°œ ì£¼ìš” íˆ¬ì/ë²¤ì²˜ ë‰´ìŠ¤ ì‚¬ì´íŠ¸
- **ì €ì¥**: Supabase ë°ì´í„°ë² ì´ìŠ¤
- **ë¶„ì„**: ë‰´ìŠ¤ ê±´ìˆ˜ ê¸°ë°˜ 1-19ìœ„ ë­í‚¹

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1ë‹¨ê³„: í™˜ê²½ ì„¤ì •

#### Python ì„¤ì¹˜ í™•ì¸
```bash
python --version  # Python 3.8 ì´ìƒ í•„ìš”
```

#### íŒ¨í‚¤ì§€ ì„¤ì¹˜
```bash
cd scripts/investment-news-scraper
pip install -r requirements.txt
```

---

### 2ë‹¨ê³„: Supabase ì„¤ì •

#### 1) Supabase í”„ë¡œì íŠ¸ ìƒì„±
1. https://supabase.com ì ‘ì†
2. ë¡œê·¸ì¸ (ì—†ìœ¼ë©´ ê°€ì…)
3. "New Project" í´ë¦­
4. í”„ë¡œì íŠ¸ëª… ì…ë ¥ ë° ìƒì„± ëŒ€ê¸° (1-2ë¶„)

#### 2) í…Œì´ë¸” ìƒì„±
1. Supabase ëŒ€ì‹œë³´ë“œ > SQL Editor ë©”ë‰´
2. `create_tables.sql` íŒŒì¼ ë‚´ìš© ë³µì‚¬
3. SQL Editorì— ë¶™ì—¬ë„£ê¸°
4. "Run" ë²„íŠ¼ í´ë¦­

âœ… **ê²°ê³¼ í™•ì¸**:
- "Table Editor" ë©”ë‰´ì—ì„œ í…Œì´ë¸” 2ê°œ í™•ì¸:
  - `investment_news_articles`
  - `investment_news_ranking`

#### 3) API í‚¤ í™•ì¸
1. Settings > API ë©”ë‰´
2. ë‹¤ìŒ ì •ë³´ ë³µì‚¬:
   - **Project URL**: `https://xxxxx.supabase.co`
   - **anon public key**: `eyJhbGc...` (ê¸´ ë¬¸ìì—´)

---

### 3ë‹¨ê³„: í™˜ê²½ë³€ìˆ˜ ì„¤ì •

#### .env íŒŒì¼ ìƒì„±
```bash
cp .env.example .env
```

#### .env íŒŒì¼ ìˆ˜ì •
```env
SUPABASE_URL=https://your-project-id.supabase.co
SUPABASE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...
```

âš ï¸ **ì‹¤ì œ ê°’ìœ¼ë¡œ ë³€ê²½í•˜ì„¸ìš”!**

---

### 4ë‹¨ê³„: ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰

```bash
python scrape_investment_news.py
```

**ì˜ˆìƒ ì†Œìš” ì‹œê°„**: 5-10ë¶„ (ì‚¬ì´íŠ¸ë³„ 2ì´ˆ ëŒ€ê¸°)

**ì‹¤í–‰ ì¤‘ ë¡œê·¸**:
```
ğŸ“° íˆ¬ì ë‰´ìŠ¤ ìŠ¤í¬ë˜í•‘ ì‹œì‘
ğŸ“… ê¸°ê°„: 2026-01-01 ~ 2026-01-25
ğŸŒ ëŒ€ìƒ ì‚¬ì´íŠ¸: 19ê°œ
==================================================
[1/19] ë”ë¸Œì´ì”¨ ì²˜ë¦¬ ì¤‘...
ğŸ” [8] ë”ë¸Œì´ì”¨ ìŠ¤í¬ë˜í•‘ ì‹œì‘...
âœ… [8] ë”ë¸Œì´ì”¨: 12ê±´ ìˆ˜ì§‘
â³ 2ì´ˆ ëŒ€ê¸° ì¤‘...
...
âœ… ìŠ¤í¬ë˜í•‘ ì™„ë£Œ!
ğŸ“Š ìˆ˜ì§‘ ê±´ìˆ˜: 234ê±´
ğŸ’¾ ì €ì¥ ê±´ìˆ˜: 234ê±´
```

---

### 5ë‹¨ê³„: ë­í‚¹ ì—…ë°ì´íŠ¸

#### Supabaseì—ì„œ SQL ì‹¤í–‰
1. Supabase ëŒ€ì‹œë³´ë“œ > SQL Editor
2. ë‹¤ìŒ SQL ì‹¤í–‰:
```sql
SELECT update_news_ranking();
```

#### ë­í‚¹ í™•ì¸
```sql
SELECT * FROM v_latest_ranking;
```

**ê²°ê³¼ ì˜ˆì‹œ**:
| rank | site_name | news_count |
|------|-----------|------------|
| 1 | ë²¤ì²˜ìŠ¤í€˜ì–´ | 45 |
| 2 | í”Œë˜í…€ | 38 |
| 3 | ë”ë¸Œì´ì”¨ | 32 |
| ... | ... | ... |

---

## ğŸ“ íŒŒì¼ êµ¬ì¡°

```
scripts/investment-news-scraper/
â”œâ”€â”€ README.md                    # ì´ íŒŒì¼
â”œâ”€â”€ PROJECT_PLAN.md              # í”„ë¡œì íŠ¸ ê³„íšì„œ
â”œâ”€â”€ create_tables.sql            # í…Œì´ë¸” ìƒì„± SQL
â”œâ”€â”€ scrape_investment_news.py    # ìŠ¤í¬ë˜í•‘ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ requirements.txt             # Python íŒ¨í‚¤ì§€ ëª©ë¡
â”œâ”€â”€ .env.example                 # í™˜ê²½ë³€ìˆ˜ ì˜ˆì‹œ
â”œâ”€â”€ .env                         # í™˜ê²½ë³€ìˆ˜ (ì§ì ‘ ìƒì„±)
â””â”€â”€ scraping_log.txt             # ì‹¤í–‰ ë¡œê·¸ (ìë™ ìƒì„±)
```

---

## ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡°

### í…Œì´ë¸” 1: `investment_news_articles`

**ìš©ë„**: ìˆ˜ì§‘ëœ ëª¨ë“  ë‰´ìŠ¤ ê¸°ì‚¬ ì €ì¥

| ì»¬ëŸ¼ | íƒ€ì… | ì„¤ëª… |
|------|------|------|
| id | SERIAL | ìë™ ì¦ê°€ ID |
| site_number | INTEGER | ì‚¬ì´íŠ¸ ë²ˆí˜¸ (8-26) |
| site_name | TEXT | ì‚¬ì´íŠ¸ëª… |
| site_url | TEXT | ì‚¬ì´íŠ¸ URL |
| article_title | TEXT | ê¸°ì‚¬ ì œëª© |
| article_url | TEXT | ê¸°ì‚¬ URL (UNIQUE) |
| published_date | DATE | ë°œí–‰ì¼ |
| content_snippet | TEXT | ë‚´ìš© ë°œì·Œ |
| collected_at | TIMESTAMP | ìˆ˜ì§‘ ì‹œê°„ |

### í…Œì´ë¸” 2: `investment_news_ranking`

**ìš©ë„**: ì‚¬ì´íŠ¸ë³„ ë‰´ìŠ¤ ê±´ìˆ˜ ì§‘ê³„ ë° ë­í‚¹

| ì»¬ëŸ¼ | íƒ€ì… | ì„¤ëª… |
|------|------|------|
| id | SERIAL | ìë™ ì¦ê°€ ID |
| site_number | INTEGER | ì‚¬ì´íŠ¸ ë²ˆí˜¸ (UNIQUE) |
| site_name | TEXT | ì‚¬ì´íŠ¸ëª… |
| site_url | TEXT | ì‚¬ì´íŠ¸ URL |
| news_count | INTEGER | ë‰´ìŠ¤ ê±´ìˆ˜ |
| rank | INTEGER | ë­í‚¹ (1-19) |
| period_start | DATE | ì§‘ê³„ ì‹œì‘ì¼ |
| period_end | DATE | ì§‘ê³„ ì¢…ë£Œì¼ |
| last_updated | TIMESTAMP | ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ |

---

## ğŸ¯ ì‚¬ì´íŠ¸ ëª©ë¡ (19ê°œ)

| ë²ˆí˜¸ | ì‚¬ì´íŠ¸ëª… | URL |
|------|---------|-----|
| 8 | ë”ë¸Œì´ì”¨ | thevc.kr |
| 9 | ë²¤ì²˜ìŠ¤í€˜ì–´ | www.venturesquare.net |
| 10 | í”Œë˜í…€ | platum.kr |
| 11 | ìŠ¤íƒ€íŠ¸ì—…íˆ¬ë°ì´ | startuptoday.kr |
| 12 | ìŠ¤íƒ€íŠ¸ì—…ì—” | startupn.kr |
| 13 | ì•„ì›ƒìŠ¤íƒ ë”© | outstanding.kr |
| 14 | ëª¨ë¹„ì¸ì‚¬ì´ë“œ | mobiinside.co.kr |
| 15 | ì§€ë””ë„·ì½”ë¦¬ì•„ | www.zdnet.co.kr |
| 16 | ë”ë²¨ | www.thebell.co.kr |
| 17 | ë„¥ìŠ¤íŠ¸ìœ ë‹ˆì½˜ | nextunicorn.kr |
| 18 | í…Œí¬ì›”ë“œë‰´ìŠ¤ | www.epnc.co.kr |
| 19 | AIíƒ€ì„ìŠ¤ | www.aitimes.com |
| 20 | ë²¤ì²˜ê²½ì˜ì‹ ë¬¸ | www.vmnews.co.kr |
| 21 | ë‰´ìŠ¤í†± | www.newstopkorea.com |
| 22 | ë¸”ë¡œí„° | www.bloter.net |
| 23 | ì´ì½”ë…¸ë¯¸ìŠ¤íŠ¸ | www.economist.co.kr |
| 24 | ë§¤ì¼ê²½ì œ MKí…Œí¬ë¦¬ë·° | www.mk.co.kr/news/it |
| 25 | ë‹¤ìŒë‰´ìŠ¤ ë²¤ì²˜/ìŠ¤íƒ€íŠ¸ì—… | news.daum.net/section/2/venture |
| 26 | ëŒ€í•œë¯¼êµ­ ì •ì±…ë¸Œë¦¬í•‘ | www.korea.kr |

---

## ğŸ”§ ìŠ¤í¬ë¦½íŠ¸ ì»¤ìŠ¤í„°ë§ˆì´ì§•

### ì‚¬ì´íŠ¸ë³„ ìŠ¤í¬ë˜í•‘ ë¡œì§ ìˆ˜ì •

`scrape_investment_news.py`ì˜ `scrape_generic_site()` í•¨ìˆ˜ëŠ” **ê¸°ë³¸ í…œí”Œë¦¿**ì…ë‹ˆë‹¤.

**ê° ì‚¬ì´íŠ¸ì˜ HTML êµ¬ì¡°ì— ë§ê²Œ ì»¤ìŠ¤í„°ë§ˆì´ì§•ì´ í•„ìš”í•©ë‹ˆë‹¤.**

#### ì˜ˆì‹œ: ë²¤ì²˜ìŠ¤í€˜ì–´
```python
def scrape_venturesquare(site: Dict) -> List[Dict]:
    """ë²¤ì²˜ìŠ¤í€˜ì–´ ì „ìš© ìŠ¤í¬ë˜í•‘"""
    articles = []
    url = 'https://www.venturesquare.net/category/investment'

    response = requests.get(url, headers=HEADERS)
    soup = BeautifulSoup(response.text, 'lxml')

    # ë²¤ì²˜ìŠ¤í€˜ì–´ì˜ ì‹¤ì œ HTML êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •
    for article_elem in soup.select('.article-list .item'):
        title = article_elem.select_one('.title').get_text(strip=True)
        article_url = article_elem.select_one('a')['href']
        date_text = article_elem.select_one('.date').get_text(strip=True)
        published_date = parse_date(date_text)

        if contains_keyword(title) and is_valid_date(published_date):
            articles.append({
                'site_number': 9,
                'site_name': 'ë²¤ì²˜ìŠ¤í€˜ì–´',
                'site_url': 'www.venturesquare.net',
                'article_title': title,
                'article_url': article_url,
                'published_date': published_date.isoformat(),
            })

    return articles
```

---

## ğŸ” ìœ ìš©í•œ SQL ì¿¼ë¦¬

### 1. ì „ì²´ ë‰´ìŠ¤ ìˆ˜ í™•ì¸
```sql
SELECT COUNT(*) as total_articles
FROM investment_news_articles
WHERE published_date BETWEEN '2026-01-01' AND CURRENT_DATE;
```

### 2. ë‚ ì§œë³„ ë‰´ìŠ¤ ê±´ìˆ˜
```sql
SELECT published_date, COUNT(*) as daily_count
FROM investment_news_articles
GROUP BY published_date
ORDER BY published_date DESC;
```

### 3. íŠ¹ì • ì‚¬ì´íŠ¸ ë‰´ìŠ¤ ëª©ë¡
```sql
SELECT article_title, article_url, published_date
FROM investment_news_articles
WHERE site_number = 9  -- ë²¤ì²˜ìŠ¤í€˜ì–´
ORDER BY published_date DESC;
```

### 4. í‚¤ì›Œë“œë³„ ê²€ìƒ‰
```sql
SELECT site_name, article_title, published_date
FROM investment_news_articles
WHERE article_title ILIKE '%ì‹œë¦¬ì¦ˆ%'
ORDER BY published_date DESC;
```

### 5. ë­í‚¹ ì¬ê³„ì‚°
```sql
SELECT update_news_ranking();
SELECT * FROM v_latest_ranking;
```

---

## âš ï¸ ì£¼ì˜ì‚¬í•­

### ë²•ì /ìœ¤ë¦¬ì 
- âœ… **robots.txt ì¤€ìˆ˜**: ê° ì‚¬ì´íŠ¸ì˜ í¬ë¡¤ë§ ì •ì±… í™•ì¸
- âœ… **ìš”ì²­ ê°„ê²©**: 2ì´ˆ ëŒ€ê¸°ë¡œ ì„œë²„ ë¶€í•˜ ë°©ì§€
- âœ… **ì €ì‘ê¶Œ**: ê¸°ì‚¬ ì „ë¬¸ì´ ì•„ë‹Œ ì œëª©/URLë§Œ ì €ì¥

### ê¸°ìˆ ì 
- âš ï¸ **ë™ì  ì‚¬ì´íŠ¸**: JavaScript ë Œë”ë§ í•„ìš” ì‹œ Selenium ì‚¬ìš©
- âš ï¸ **ì‚¬ì´íŠ¸ êµ¬ì¡° ë³€ê²½**: ì •ê¸°ì ìœ¼ë¡œ ìŠ¤í¬ë˜í•‘ ë¡œì§ ì ê²€ í•„ìš”
- âš ï¸ **ì—ëŸ¬ ì²˜ë¦¬**: ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ì‹œ ì¬ì‹œë„ ë¡œì§ ì¶”ê°€ ê³ ë ¤

### ë³´ì•ˆ
- ğŸ”’ **.env íŒŒì¼**: ì ˆëŒ€ Gitì— ì»¤ë°‹í•˜ì§€ ì•Šê¸° (`.gitignore` í™•ì¸)
- ğŸ”’ **Supabase Key**: anon key ì‚¬ìš© (service_role key ì‚¬ìš© ê¸ˆì§€)

---

## ğŸ› ë¬¸ì œ í•´ê²°

### 1. íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì˜¤ë¥˜
```bash
# pip ì—…ê·¸ë ˆì´ë“œ
python -m pip install --upgrade pip

# ê°œë³„ ì„¤ì¹˜
pip install requests beautifulsoup4 lxml supabase python-dotenv
```

### 2. Supabase ì—°ê²° ì˜¤ë¥˜
- `.env` íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
- SUPABASE_URLê³¼ SUPABASE_KEYê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸
- Supabase í”„ë¡œì íŠ¸ê°€ í™œì„±í™”ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸

### 3. ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨
- ì‚¬ì´íŠ¸ê°€ ì ‘ê·¼ ê°€ëŠ¥í•œì§€ ë¸Œë¼ìš°ì €ì—ì„œ í™•ì¸
- `scraping_log.txt` íŒŒì¼ì—ì„œ ì—ëŸ¬ ë©”ì‹œì§€ í™•ì¸
- íŠ¹ì • ì‚¬ì´íŠ¸ë§Œ ì‹¤íŒ¨ ì‹œ: HTML êµ¬ì¡° ë³€ê²½ ê°€ëŠ¥ì„±

### 4. ì¤‘ë³µ URL ì—ëŸ¬
- ì •ìƒ ë™ì‘ (ì´ë¯¸ ìˆ˜ì§‘ëœ ê¸°ì‚¬ëŠ” ìë™ ìŠ¤í‚µ)
- ë¡œê·¸ì— "âš ï¸ ì¤‘ë³µ URL ê°ì§€" ë©”ì‹œì§€ ì¶œë ¥

---

## ğŸ“Š ë°ì´í„° ë¶„ì„ (ì¬ë¯¸ë‚˜ ICI)

### Pythonìœ¼ë¡œ ë­í‚¹ ì¡°íšŒ
```python
from supabase import create_client
import os
from dotenv import load_dotenv

load_dotenv()
supabase = create_client(os.getenv('SUPABASE_URL'), os.getenv('SUPABASE_KEY'))

# ë­í‚¹ ì—…ë°ì´íŠ¸
supabase.rpc('update_news_ranking').execute()

# ë­í‚¹ ì¡°íšŒ
ranking = supabase.table('investment_news_ranking').select('*').order('rank').execute()

for site in ranking.data:
    print(f"{site['rank']}ìœ„: {site['site_name']} ({site['news_count']}ê±´)")
```

---

## ğŸ“ ë¬¸ì˜

**ì‘ì„±ì**: Claude Code (AI Assistant)
**ì‘ì„±ì¼**: 2026-01-25
**í”„ë¡œì íŠ¸**: íˆ¬ì ë‰´ìŠ¤ ìŠ¤í¬ë˜í•‘ ë° ë­í‚¹ ì‹œìŠ¤í…œ

---

## ğŸ“ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” êµìœ¡ ë° ë¶„ì„ ëª©ì ìœ¼ë¡œ ì œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.
ê° ë‰´ìŠ¤ ì‚¬ì´íŠ¸ì˜ ì´ìš©ì•½ê´€ì„ ì¤€ìˆ˜í•´ì£¼ì„¸ìš”.
