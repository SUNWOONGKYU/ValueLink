#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ìµœì¢… ë¯¸ë°œê²¬ 5ê°œ ê¸°ì—… ì¬ê²€ìƒ‰
"""

import os
import sys
import csv
import requests
from datetime import datetime
from dotenv import load_dotenv
from supabase import create_client, Client
import time

# UTF-8 ì¶œë ¥ ì„¤ì •
if sys.platform == 'win32':
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')

load_dotenv()

supabase: Client = create_client(
    os.getenv("SUPABASE_URL"),
    os.getenv("SUPABASE_SERVICE_KEY")
)

NAVER_CLIENT_ID = os.getenv("NAVER_CLIENT_ID")
NAVER_CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET")

GEMINI_CSV = 'sensible_companies_2026_01_GEMINI.csv'

# ë¯¸ë°œê²¬ 5ê°œ ê¸°ì—…
missing_companies = [
    'ë‰´íƒ€ì…ì¸ë”ìŠ¤íŠ¸ë¦¬ì¦ˆ',
    'ë±ì‚¬ìŠ¤íŠœë””ì˜¤',
    'ë””ì•¤í‹°í…Œí¬ì†”ë£¨ì…˜',
    'ì—˜ë¦¬ì‹œì „',
    'í©í‹°ë¥´ë‚˜í…Œë¼í“¨í‹±ìŠ¤'
]

print("=" * 80)
print("ìµœì¢… ë¯¸ë°œê²¬ 5ê°œ ê¸°ì—… ì¬ê²€ìƒ‰")
print("=" * 80)

# 1. Gemini CSVì—ì„œ íˆ¬ìì ì •ë³´ í™•ì¸
company_info = {}
with open(GEMINI_CSV, 'r', encoding='utf-8') as f:
    reader = csv.DictReader(f)
    for row in reader:
        company_name = row['ê¸°ì—…ëª…']
        if company_name in missing_companies:
            company_info[company_name] = {
                'íˆ¬ìì': row.get('íˆ¬ìì', ''),
                'ì£¼ìš”ì‚¬ì—…': row.get('ì£¼ìš”ì‚¬ì—…', ''),
                'ë‹¨ê³„': row.get('ë‹¨ê³„', ''),
                'ì‹ ê·œ': row.get('ì‹ ê·œ', '')
            }

print("\nğŸ“‹ ë¯¸ë°œê²¬ 5ê°œ ê¸°ì—… ì •ë³´:")
for company, info in company_info.items():
    print(f"\n{company}:")
    print(f"  íˆ¬ìì: {info['íˆ¬ìì']}")
    print(f"  ì£¼ìš”ì‚¬ì—…: {info['ì£¼ìš”ì‚¬ì—…']}")
    print(f"  ë‹¨ê³„: {info['ë‹¨ê³„']}")
    print(f"  ì‹ ê·œ: {info['ì‹ ê·œ']}")

# 2. ë„¤ì´ë²„ APIë¡œ ê²€ìƒ‰
def search_naver(company_name, investor):
    url = "https://openapi.naver.com/v1/search/news.json"

    headers = {
        'X-Naver-Client-Id': NAVER_CLIENT_ID,
        'X-Naver-Client-Secret': NAVER_CLIENT_SECRET
    }

    # ê²€ìƒ‰ ì¿¼ë¦¬ ì—¬ëŸ¬ ê°œ ì‹œë„
    queries = [
        f"{company_name} {investor} íˆ¬ì",
        f"{company_name} íˆ¬ììœ ì¹˜",
        f"{company_name} íˆ¬ì",
        company_name
    ]

    for query in queries:
        params = {
            'query': query,
            'display': 100,
            'sort': 'date'
        }

        try:
            response = requests.get(url, headers=headers, params=params, timeout=10)

            if response.status_code == 200:
                items = response.json().get('items', [])

                for item in items:
                    title = item.get('title', '').replace('<b>', '').replace('</b>', '')
                    link = item.get('originallink') or item.get('link')
                    pub_date = item.get('pubDate', '')

                    # ê¸°ì—…ëª… í™•ì¸
                    if company_name not in title:
                        continue

                    # íˆ¬ì í‚¤ì›Œë“œ í™•ì¸
                    investment_keywords = ['íˆ¬ì', 'ìœ ì¹˜', 'í€ë”©', 'ì‹œë¦¬ì¦ˆ', 'Series', 'ë¼ìš´ë“œ']
                    if any(kw in title for kw in investment_keywords):
                        # ë‚ ì§œ íŒŒì‹±
                        try:
                            dt = datetime.strptime(pub_date, '%a, %d %b %Y %H:%M:%S %z')
                            published_date = dt.strftime('%Y-%m-%d')
                        except:
                            published_date = datetime.now().strftime('%Y-%m-%d')

                        # ì‚¬ì´íŠ¸ëª…
                        site_mapping = {
                            'wowtale.net': ('WOWTALE', 1),
                            'venturesquare.net': ('ë²¤ì²˜ìŠ¤í€˜ì–´', 9),
                            'thebell.co.kr': ('ë”ë²¨', 16),
                            'platum.kr': ('í”Œë˜í…€', 10),
                            'startuptoday.kr': ('ìŠ¤íƒ€íŠ¸ì—…íˆ¬ë°ì´', 11),
                        }

                        site_name = "ë„¤ì´ë²„ ë‰´ìŠ¤"
                        site_number = 99

                        for domain, (name, num) in site_mapping.items():
                            if domain in link:
                                site_name = name
                                site_number = num
                                break

                        return {
                            'site_number': site_number,
                            'site_name': site_name,
                            'site_url': '',
                            'article_title': title,
                            'article_url': link,
                            'published_date': published_date
                        }, query

            time.sleep(0.1)

        except Exception as e:
            continue

    return None, None

# 3. ê²€ìƒ‰ ì‹¤í–‰
print("\n" + "=" * 80)
print("ì¬ê²€ìƒ‰ ì‹œì‘")
print("=" * 80)

found = 0
not_found = []

for idx, company in enumerate(missing_companies, 1):
    print(f"\n[{idx}/5] {company}")

    info = company_info.get(company, {})
    investor = info.get('íˆ¬ìì', '')

    article, query = search_naver(company, investor)

    if article:
        print(f"  âœ… ë°œê²¬: {article['article_title'][:60]}...")
        print(f"  ğŸ” ê²€ìƒ‰ì–´: {query}")
        print(f"  ğŸ“° [{article['site_name']}]")

        # ì¤‘ë³µ í™•ì¸
        existing = supabase.table("investment_news_articles")\
            .select("id")\
            .eq("article_url", article['article_url'])\
            .execute()

        if not existing.data:
            try:
                supabase.table("investment_news_articles").insert(article).execute()
                print(f"  ğŸ’¾ DB ì €ì¥ ì™„ë£Œ")
                found += 1
            except Exception as e:
                print(f"  âŒ DB ì˜¤ë¥˜: {e}")
        else:
            print(f"  âš ï¸  ì¤‘ë³µ")
            found += 1
    else:
        print(f"  âŒ ëª» ì°¾ìŒ")
        not_found.append(company)

    time.sleep(0.5)

print(f"\n{'='*80}")
print("ì¬ê²€ìƒ‰ ì™„ë£Œ")
print(f"{'='*80}")
print(f"âœ… ë°œê²¬: {found}ê°œ")
print(f"âŒ ìµœì¢… ë¯¸ë°œê²¬: {len(not_found)}ê°œ")

if not_found:
    print(f"\nâŒ ìµœì¢… ë¯¸ë°œê²¬ ê¸°ì—…:")
    for company in not_found:
        print(f"  - {company}")

# ìµœì¢… í†µê³„
count_result = supabase.table("investment_news_articles").select("id", count="exact").execute()
print(f"\ninvestment_news_articles í…Œì´ë¸” ì´ ë ˆì½”ë“œ: {count_result.count}ê°œ")
