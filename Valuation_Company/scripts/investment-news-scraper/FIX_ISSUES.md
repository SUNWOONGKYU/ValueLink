# ìŠ¤í¬ë˜í•‘ ì´ìŠˆ ìˆ˜ì • ê°€ì´ë“œ

**ì‘ì„±ì¼**: 2026-01-25
**ëŒ€ìƒ**: ì¬ë¯¸ë‚˜ ICI

---

## ğŸ”´ ë°œê²¬ëœ ë¬¸ì œ

### 1. í…Œì´ë¸” ì—†ìŒ ì˜¤ë¥˜
**ì˜¤ë¥˜ ë©”ì‹œì§€**: `investment_news_articles` í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ

**ì›ì¸**: ì‚¬ìš©ìê°€ `create_tables.sql`ì„ Supabaseì—ì„œ ì‹¤í–‰í•˜ì§€ ì•Šì•˜ì„ ê°€ëŠ¥ì„±

**í•´ê²° ë°©ë²•**:
1. ì‚¬ìš©ìì—ê²Œ í™•ì¸ ìš”ì²­
2. Supabase SQL Editorì—ì„œ ë‹¤ìŒ ì¿¼ë¦¬ ì‹¤í–‰:
   ```sql
   SELECT table_name
   FROM information_schema.tables
   WHERE table_schema = 'public'
   AND table_name IN ('investment_news_articles', 'investment_news_ranking');
   ```
3. í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ `create_tables.sql` ì „ì²´ë¥¼ Supabaseì—ì„œ ì‹¤í–‰

---

### 2. SSL ì˜¤ë¥˜ - ë²¤ì²˜ê²½ì˜ì‹ ë¬¸ (ì‚¬ì´íŠ¸ 20)

**ì˜¤ë¥˜ ë©”ì‹œì§€**:
```
HTTPSConnectionPool(host='www.vmnews.co.kr', port=443):
Max retries exceeded with url: / (Caused by SSLError)
```

**í•´ê²° ë°©ë²•**: `scrape_site_dispatch` í•¨ìˆ˜ ìˆ˜ì •

**ìˆ˜ì • ìœ„ì¹˜**: `scrape_investment_news.py` ë¼ì¸ 331-370

**ìˆ˜ì • ì½”ë“œ**:
```python
def scrape_site_dispatch(site: Dict) -> List[Dict]:
    articles = []
    site_number = site['number']
    site_name = site['name']
    site_url = site['url']

    logger.info(f"ğŸ” [{site_number}] {site_name} ìŠ¤í¬ë˜í•‘ ì‹œì‘...")

    try:
        # SSL ê²€ì¦ ë¹„í™œì„±í™”ê°€ í•„ìš”í•œ ì‚¬ì´íŠ¸
        verify_ssl = True
        if site_number == 20:  # ë²¤ì²˜ê²½ì˜ì‹ ë¬¸
            verify_ssl = False
            logger.warning(f"âš ï¸ [{site_number}] {site_name}: SSL ê²€ì¦ ë¹„í™œì„±í™”")

        # ì‚¬ì´íŠ¸ ë©”ì¸ í˜ì´ì§€ ìš”ì²­
        response = requests.get(site_url, headers=HEADERS, timeout=10, verify=verify_ssl)
        response.raise_for_status()
        response.encoding = 'utf-8'

        soup = BeautifulSoup(response.text, 'lxml')

        # í•´ë‹¹ ì‚¬ì´íŠ¸ì— ë§ëŠ” ìŠ¤í¬ë˜í¼ í•¨ìˆ˜ í˜¸ì¶œ
        scraper_func = SITE_SCRAPERS.get(site_url)
        if scraper_func:
            articles = scraper_func(soup, site)
        else:
            logger.error(f"âŒ [{site_number}] {site_name}ì— ëŒ€í•œ ìŠ¤í¬ë˜í¼ í•¨ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        logger.info(f"âœ… [{site_number}] {site_name}: {len(articles)}ê±´ ìˆ˜ì§‘")

    except requests.RequestException as e:
        logger.error(f"âŒ [{site_number}] {site_name} ìš”ì²­ ì‹¤íŒ¨: {e}")
    except Exception as e:
        logger.error(f"âŒ [{site_number}] {site_name} ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜: {e}")

    return articles
```

**ë³€ê²½ ì‚¬í•­**:
- `verify_ssl` ë³€ìˆ˜ ì¶”ê°€
- ì‚¬ì´íŠ¸ 20ë²ˆ(ë²¤ì²˜ê²½ì˜ì‹ ë¬¸)ì¼ ë•Œ `verify=False` ì„¤ì •
- `requests.get()`ì— `verify=verify_ssl` íŒŒë¼ë¯¸í„° ì¶”ê°€

---

### 3. 404 ì˜¤ë¥˜ - ë‹¤ìŒë‰´ìŠ¤ (ì‚¬ì´íŠ¸ 25)

**ì˜¤ë¥˜ ë©”ì‹œì§€**:
```
404 Client Error: Not Found for url: https://news.daum.net/section/2/venture
```

**ì›ì¸**: URLì´ ë³€ê²½ë˜ì—ˆê±°ë‚˜ ì¡´ì¬í•˜ì§€ ì•ŠìŒ

**í•´ê²° ë°©ë²• 1**: URL ìˆ˜ì •

ë‹¤ìŒë‰´ìŠ¤ì˜ ì‹¤ì œ ë²¤ì²˜/ìŠ¤íƒ€íŠ¸ì—… ì„¹ì…˜ URL í™•ì¸ í•„ìš”:
- ì˜µì…˜ A: `https://news.daum.net/breakingnews/economic/venture`
- ì˜µì…˜ B: `https://news.daum.net/economic#venture`
- ì˜µì…˜ C: ê²€ìƒ‰ URL ì‚¬ìš©

**ìˆ˜ì • ìœ„ì¹˜**: `scrape_investment_news.py` ë¼ì¸ 66

**Before**:
```python
{'number': 25, 'name': 'ë‹¤ìŒë‰´ìŠ¤ ë²¤ì²˜/ìŠ¤íƒ€íŠ¸ì—…', 'url': 'https://news.daum.net/section/2/venture'},
```

**After** (ì˜µì…˜ A):
```python
{'number': 25, 'name': 'ë‹¤ìŒë‰´ìŠ¤ ë²¤ì²˜/ìŠ¤íƒ€íŠ¸ì—…', 'url': 'https://news.daum.net/breakingnews/economic/venture'},
```

**í•´ê²° ë°©ë²• 2**: ë¸Œë¼ìš°ì €ë¡œ í™•ì¸

1. https://news.daum.net ì ‘ì†
2. "ê²½ì œ" ë˜ëŠ” "IT/ê³¼í•™" ì„¹ì…˜ í™•ì¸
3. "ë²¤ì²˜" ë˜ëŠ” "ìŠ¤íƒ€íŠ¸ì—…" ì¹´í…Œê³ ë¦¬ ì°¾ê¸°
4. ì‹¤ì œ URL í™•ì¸ í›„ ìˆ˜ì •

**í•´ê²° ë°©ë²• 3**: ë‹¤ìŒ ê²€ìƒ‰ ì‚¬ìš©

```python
{'number': 25, 'name': 'ë‹¤ìŒë‰´ìŠ¤ ë²¤ì²˜/ìŠ¤íƒ€íŠ¸ì—…', 'url': 'https://search.daum.net/search?w=news&q=íˆ¬ììœ ì¹˜'},
```

---

## ğŸ“‹ ìˆ˜ì • ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì‚¬ìš©ì í™•ì¸ ì‚¬í•­
- [ ] Supabaseì—ì„œ í…Œì´ë¸” ì¡´ì¬ í™•ì¸
- [ ] í…Œì´ë¸” ì—†ìœ¼ë©´ `create_tables.sql` ì‹¤í–‰
- [ ] í…Œì´ë¸” ìƒì„± í™•ì¸ ì¿¼ë¦¬ ì‹¤í–‰

### ì¬ë¯¸ë‚˜ ICI ìˆ˜ì • ì‚¬í•­
- [ ] `scrape_site_dispatch` í•¨ìˆ˜ì— SSL ê²€ì¦ ë¹„í™œì„±í™” ë¡œì§ ì¶”ê°€
- [ ] ë‹¤ìŒë‰´ìŠ¤ URL í™•ì¸ ë° ìˆ˜ì •
- [ ] ìˆ˜ì •ëœ ìŠ¤í¬ë¦½íŠ¸ í…ŒìŠ¤íŠ¸
- [ ] ì¬ì‹¤í–‰í•˜ì—¬ ë°ì´í„° ìˆ˜ì§‘ í™•ì¸

---

## ğŸš€ ìˆ˜ì • í›„ ì‹¤í–‰ ìˆœì„œ

1. **ì‚¬ìš©ì**: Supabase í…Œì´ë¸” í™•ì¸ ë° ìƒì„±
2. **ì¬ë¯¸ë‚˜ ICI**: ìŠ¤í¬ë¦½íŠ¸ ìˆ˜ì •
3. **ì¬ë¯¸ë‚˜ ICI**: ìŠ¤í¬ë¦½íŠ¸ ì¬ì‹¤í–‰
   ```bash
   python scrape_investment_news.py
   ```
4. **í™•ì¸**: Supabaseì—ì„œ ë°ì´í„° ìˆ˜ì§‘ ì—¬ë¶€ í™•ì¸
   ```sql
   SELECT COUNT(*) FROM investment_news_articles;
   SELECT site_name, COUNT(*) FROM investment_news_articles GROUP BY site_name;
   ```

---

## ğŸ“ ì¶”ê°€ ì§€ì›

ìˆ˜ì • í›„ì—ë„ ë¬¸ì œê°€ ë°œìƒí•˜ë©´:
- ë¡œê·¸ íŒŒì¼ í™•ì¸: `scraping_log.txt`
- íŠ¹ì • ì‚¬ì´íŠ¸ ì—ëŸ¬ ë©”ì‹œì§€ ê³µìœ 
- ë¸Œë¼ìš°ì €ì—ì„œ í•´ë‹¹ ì‚¬ì´íŠ¸ ì ‘ì† ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
