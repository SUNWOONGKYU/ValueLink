#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ëª» ì°¾ì€ 6ê°œ ê¸°ì—… ìµœì¢… ê²€ìƒ‰ (ë‹¤ì–‘í•œ ê²€ìƒ‰ì–´ ì¡°í•©)
"""

import os
import sys
import requests
from datetime import datetime
from dotenv import load_dotenv
from supabase import create_client, Client
import time

# UTF-8 ì¶œë ¥ ì„¤ì •
if sys.platform == 'win32':
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')

load_dotenv()

supabase: Client = create_client(
    os.getenv("SUPABASE_URL"),
    os.getenv("SUPABASE_SERVICE_KEY")
)

NAVER_CLIENT_ID = os.getenv("NAVER_CLIENT_ID")
NAVER_CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET")

# ëª» ì°¾ì€ 6ê°œ ê¸°ì—… - ë‹¤ì–‘í•œ ê²€ìƒ‰ì–´ ë³€í˜•
companies_variants = {
    "ë¶€ìŠ¤í‹°ìŠ¤": ["ë¶€ìŠ¤í‹°ìŠ¤", "Boostis", "ë¶€ìŠ¤íŠ¸ì´ì—ìŠ¤", "ì‹¬ë¦¬ë°œë‹¬ ê²€ì§„"],
    "ì• í”Œì—ì´ì•„ì´": ["ì• í”Œì—ì´ì•„ì´", "ì• í”ŒAI", "Apple AI"],
    "ìŠ¤íŠœë””ì˜¤ì—í”¼ì†Œë“œ": ["ìŠ¤íŠœë””ì˜¤ì—í”¼ì†Œë“œ", "Studio Episode", "ìŠ¤íŠœë””ì˜¤ ì—í”¼ì†Œë“œ"],
    "ë¹„ë°”íŠ¸ë¡œë¡œë³´í‹±ìŠ¤": ["ë¹„ë°”íŠ¸ë¡œë¡œë³´í‹±ìŠ¤", "Vivatro Robotics", "ë¹„ë°”íŠ¸ë¡œ"],
    "ì†Œì…œë¦­ìŠ¤ì½”ë¦¬ì•„": ["ì†Œì…œë¦­ìŠ¤ì½”ë¦¬ì•„", "Socialix Korea", "ì†Œì…œë¦­ìŠ¤"],
    "ìŠ¤ì¹´ì´ì¸í…”ë¦¬ì „ìŠ¤": ["ìŠ¤ì¹´ì´ì¸í…”ë¦¬ì „ìŠ¤", "SKY Intelligence", "ìŠ¤ì¹´ì´ ì¸í…”ë¦¬ì „ìŠ¤"]
}


def search_naver_variants(company_name, variants):
    """ë„¤ì´ë²„ API - ì—¬ëŸ¬ ë³€í˜• ê²€ìƒ‰ì–´ë¡œ ê²€ìƒ‰"""

    url = "https://openapi.naver.com/v1/search/news.json"

    headers = {
        'X-Naver-Client-Id': NAVER_CLIENT_ID,
        'X-Naver-Client-Secret': NAVER_CLIENT_SECRET
    }

    # ëª¨ë“  ë³€í˜• ì‹œë„
    for variant in variants:
        # ì—¬ëŸ¬ ê²€ìƒ‰ ì¿¼ë¦¬
        queries = [
            f"{variant} íˆ¬ììœ ì¹˜",
            f"{variant} íˆ¬ì",
            f"{variant} ì‹œë¦¬ì¦ˆ",
            f"{variant} í€ë”©",
            f"{variant} VC",
            variant
        ]

        for query in queries:
            params = {
                'query': query,
                'display': 50,
                'sort': 'date'
            }

            try:
                response = requests.get(url, headers=headers, params=params, timeout=10)

                if response.status_code == 200:
                    items = response.json().get('items', [])

                    for item in items:
                        title = item.get('title', '').replace('<b>', '').replace('</b>', '')
                        link = item.get('originallink') or item.get('link')
                        pub_date = item.get('pubDate', '')

                        # ì›ë˜ ê¸°ì—…ëª…ì´ë‚˜ ë³€í˜• ì¤‘ í•˜ë‚˜ë¼ë„ í¬í•¨
                        found = False
                        for v in variants:
                            if v in title:
                                found = True
                                break

                        if not found:
                            continue

                        # íˆ¬ì í‚¤ì›Œë“œ
                        investment_keywords = ['íˆ¬ì', 'ìœ ì¹˜', 'í€ë”©', 'ì‹œë¦¬ì¦ˆ', 'Series', 'ë¼ìš´ë“œ', 'VC', 'M&A', 'ì¸ìˆ˜']
                        if not any(kw in title for kw in investment_keywords):
                            continue

                        # ë‚ ì§œ íŒŒì‹±
                        try:
                            dt = datetime.strptime(pub_date, '%a, %d %b %Y %H:%M:%S %z')
                            published_date = dt.strftime('%Y-%m-%d')
                        except:
                            published_date = datetime.now().strftime('%Y-%m-%d')

                        # ì‚¬ì´íŠ¸ëª…
                        site_mapping = {
                            'venturesquare.net': ('ë²¤ì²˜ìŠ¤í€˜ì–´', 9),
                            'wowtale.net': ('WOWTALE', 1),
                            'platum.kr': ('í”Œë˜í…€', 10),
                            'outstanding.kr': ('ì•„ì›ƒìŠ¤íƒ ë”©', 13),
                            'startuptoday.kr': ('ìŠ¤íƒ€íŠ¸ì—…íˆ¬ë°ì´', 11),
                            'thebell.co.kr': ('ë”ë²¨', 16),
                        }

                        site_name = "ë„¤ì´ë²„ ë‰´ìŠ¤"
                        site_number = 99

                        for domain, (name, num) in site_mapping.items():
                            if domain in link:
                                site_name = name
                                site_number = num
                                break

                        return {
                            'site_number': site_number,
                            'site_name': site_name,
                            'site_url': "",
                            'article_title': title,
                            'article_url': link,
                            'published_date': published_date
                        }, variant, query

                time.sleep(0.1)

            except Exception as e:
                continue

    return None, None, None


def main():
    print("=" * 80)
    print("ëª» ì°¾ì€ 6ê°œ ê¸°ì—… ìµœì¢… ê²€ìƒ‰ (ë‹¤ì–‘í•œ ê²€ìƒ‰ì–´ ë³€í˜•)")
    print("=" * 80)

    found = 0
    duplicate = 0
    not_found = []

    for idx, (company, variants) in enumerate(companies_variants.items(), 1):
        print(f"\n[{idx}/6] {company:25s}")
        print(f"     ë³€í˜•: {', '.join(variants)}")

        # ë³€í˜• ê²€ìƒ‰
        article, matched_variant, matched_query = search_naver_variants(company, variants)

        if article and article['article_url']:
            print(f"  âœ… ë°œê²¬: {article['article_title'][:60]}...")
            print(f"  ğŸ” ê²€ìƒ‰ì–´: {matched_variant} - {matched_query}")
            print(f"  ğŸ“° [{article['site_name']}]")

            # ì¤‘ë³µ í™•ì¸
            existing = supabase.table("investment_news_articles")\
                .select("id")\
                .eq("article_url", article['article_url'])\
                .execute()

            if not existing.data:
                try:
                    supabase.table("investment_news_articles").insert(article).execute()
                    print(f"  ğŸ’¾ DB ì €ì¥ ì™„ë£Œ")
                    found += 1
                except:
                    print(f"  âŒ DB ì˜¤ë¥˜")
            else:
                print(f"  âš ï¸  ì¤‘ë³µ")
                duplicate += 1
        else:
            print(f"  âŒ ëª» ì°¾ìŒ")
            not_found.append(company)

        time.sleep(0.5)

    print(f"\n{'='*80}")
    print("ìµœì¢… ê²€ìƒ‰ ì™„ë£Œ")
    print(f"{'='*80}")
    print(f"âœ… ìƒˆë¡œ ë°œê²¬: {found}ê°œ")
    print(f"âš ï¸ ì¤‘ë³µ: {duplicate}ê°œ")
    print(f"âŒ ìµœì¢… ë¯¸ë°œê²¬: {len(not_found)}ê°œ")
    print(f"{'='*80}")

    # ìµœì¢… í†µê³„
    count_result = supabase.table("investment_news_articles").select("id", count="exact").execute()
    print(f"\ninvestment_news_articles í…Œì´ë¸” ì´ ë ˆì½”ë“œ: {count_result.count}ê°œ")

    if not_found:
        print(f"\nâŒ ìµœì¢… ë¯¸ë°œê²¬ ê¸°ì—… ({len(not_found)}ê°œ):")
        for company in not_found:
            print(f"  - {company}")
    else:
        print(f"\nğŸ‰ ëª¨ë“  ê¸°ì—… ìˆ˜ì§‘ ì™„ë£Œ!")


if __name__ == '__main__':
    main()
