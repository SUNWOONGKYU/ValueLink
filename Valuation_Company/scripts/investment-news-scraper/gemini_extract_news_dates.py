#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Gemini 2.5 Flashë¡œ ë‰´ìŠ¤ ê²Œì¬ ì‹œê°„ ì¶”ì¶œ
URLì—ì„œ ë‚ ì§œ ëª» ì°¾ì€ 76ê°œ ì²˜ë¦¬
"""

import os
import sys
import json
import time
from datetime import datetime
from dotenv import load_dotenv
from google import genai
from google.genai import types
from supabase import create_client, Client

# UTF-8 ì¶œë ¥ ì„¤ì •
if sys.platform == 'win32':
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')

load_dotenv()

# Gemini í´ë¼ì´ì–¸íŠ¸
gemini_client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))

# Supabase í´ë¼ì´ì–¸íŠ¸
supabase: Client = create_client(
    os.getenv("SUPABASE_URL"),
    os.getenv("SUPABASE_SERVICE_KEY")
)

print("=" * 80)
print("Gemini 2.5 Flash - ë‰´ìŠ¤ ê²Œì¬ ì‹œê°„ ì¶”ì¶œ")
print("=" * 80)

def extract_date_with_gemini(url, company_name):
    """Geminië¡œ ë‰´ìŠ¤ í˜ì´ì§€ ì ‘ì†í•´ì„œ ê²Œì¬ì¼ ì¶”ì¶œ"""

    prompt = f"""
ë‹¤ìŒ URLì˜ ë‰´ìŠ¤ ê¸°ì‚¬ í˜ì´ì§€ë¥¼ í™•ì¸í•˜ê³ , ì •í™•í•œ ê²Œì¬ì¼(ë°œí–‰ì¼)ì„ ì°¾ì•„ì£¼ì„¸ìš”:

**URL**: {url}
**ê¸°ì—…ëª…**: {company_name}

**ì°¾ì•„ì•¼ í•  ì •ë³´:**
- ê¸°ì‚¬ ê²Œì¬ì¼/ë°œí–‰ì¼ (published date)
- ê¸°ì‚¬ ì‘ì„±ì¼ (written date)

**ì¤‘ìš”:**
- ì‹¤ì œ ë‰´ìŠ¤ê°€ ë°œí–‰ëœ ë‚ ì§œë¥¼ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤
- DB ì €ì¥ ì‹œê°„ì´ë‚˜ ìˆ˜ì • ì‹œê°„ì´ ì•„ë‹™ë‹ˆë‹¤
- ë©”íƒ€ë°ì´í„°, ë³¸ë¬¸ ìƒë‹¨, URL ë“±ì—ì„œ ë‚ ì§œë¥¼ í™•ì¸í•˜ì„¸ìš”

**ì¶œë ¥ í˜•ì‹ (JSON):**
```json
{{
    "published_date": "YYYY-MM-DD",
    "source": "ì–´ë””ì„œ ì°¾ì•˜ëŠ”ì§€ (ì˜ˆ: ë³¸ë¬¸ ìƒë‹¨, ë©”íƒ€ë°ì´í„°, URL)"
}}
```

ë‚ ì§œë¥¼ ì°¾ì§€ ëª»í–ˆìœ¼ë©´:
```json
{{
    "published_date": null,
    "source": "ë‚ ì§œ ì •ë³´ ì—†ìŒ"
}}
```
"""

    try:
        response = gemini_client.models.generate_content(
            model='gemini-2.5-flash',
            contents=prompt,
            config=types.GenerateContentConfig(
                temperature=0.1,
                max_output_tokens=1024,
                tools=[types.Tool(google_search=types.GoogleSearch())]
            )
        )

        if not response or not hasattr(response, 'text'):
            return {"published_date": None, "source": "ì‘ë‹µ ì—†ìŒ"}

        text = response.text.strip()

        # JSON ì¶”ì¶œ (ë” robustí•˜ê²Œ)
        if "```json" in text:
            json_start = text.find("```json") + 7
            json_end = text.rfind("```")  # ë§ˆì§€ë§‰ ``` ì°¾ê¸°
            if json_end > json_start:
                text = text[json_start:json_end].strip()
        elif "```" in text:
            json_start = text.find("```") + 3
            json_end = text.rfind("```")
            if json_end > json_start:
                text = text[json_start:json_end].strip()

        # JSON íŒŒì‹± ì‹œë„
        try:
            result = json.loads(text)
            return result
        except json.JSONDecodeError:
            # JSONì´ ì•„ë‹ˆë©´ í…ìŠ¤íŠ¸ì—ì„œ ë‚ ì§œ ì¶”ì¶œ ì‹œë„
            import re
            date_match = re.search(r'(\d{4}-\d{2}-\d{2})', text)
            if date_match:
                return {
                    "published_date": date_match.group(1),
                    "source": "í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ"
                }
            else:
                return {"published_date": None, "source": f"JSON íŒŒì‹± ì‹¤íŒ¨: {text[:100]}"}

    except Exception as e:
        print(f"    âŒ Gemini ì˜¤ë¥˜: {e}")
        return {"published_date": None, "source": f"ì˜¤ë¥˜: {str(e)[:50]}"}

# Deal í…Œì´ë¸”ì—ì„œ ë‰´ìŠ¤ URL ìˆëŠ” ì „ì²´ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
print("\nğŸ“‹ ì „ì²´ Deal ì¡°íšŒ ì¤‘...")
deals = supabase.table("deals")\
    .select("*")\
    .not_.is_("news_url", "null")\
    .order("number")\
    .execute()

print(f"ì´ {len(deals.data)}ê°œ Deal (ë‰´ìŠ¤ URL ìˆìŒ)")

# ìš°ì„ ìˆœìœ„: 2026-01-28 ë¨¼ì € ì²˜ë¦¬
deals_priority = [d for d in deals.data if d.get('news_date') == '2026-01-28']
deals_other = [d for d in deals.data if d.get('news_date') != '2026-01-28']

print(f"  - 2026-01-28 (ìš°ì„ ): {len(deals_priority)}ê°œ")
print(f"  - ê¸°íƒ€: {len(deals_other)}ê°œ")

# ì „ì²´ ì²˜ë¦¬
deals_to_process = deals.data
print(f"\nì²˜ë¦¬í•  Deal: {len(deals_to_process)}ê°œ (ì „ì²´)")

update_count = 0
failed = []

for idx, deal in enumerate(deals.data, 1):
    company = deal['company_name']
    url = deal.get('news_url')

    if not url:
        print(f"\n[{idx}/{len(deals.data)}] {company}: URL ì—†ìŒ")
        continue

    print(f"\n[{idx}/{len(deals.data)}] {company}")
    print(f"  URL: {url[:70]}...")

    # Geminië¡œ ë‚ ì§œ ì¶”ì¶œ
    result = extract_date_with_gemini(url, company)

    if result.get('published_date'):
        extracted_date = result['published_date']
        source = result.get('source', 'N/A')

        print(f"  âœ… ë°œê²¬: {extracted_date} (ì¶œì²˜: {source})")

        # Deal í…Œì´ë¸” ì—…ë°ì´íŠ¸
        supabase.table("deals")\
            .update({'news_date': extracted_date})\
            .eq("id", deal['id'])\
            .execute()

        # ë‰´ìŠ¤ í…Œì´ë¸”ë„ ì—…ë°ì´íŠ¸
        supabase.table("investment_news_articles")\
            .update({'published_date': extracted_date})\
            .eq("article_url", url)\
            .execute()

        update_count += 1
    else:
        source = result.get('source', 'N/A')
        print(f"  âš ï¸  ë‚ ì§œ ì—†ìŒ: {source}")
        failed.append({
            'company': company,
            'url': url,
            'reason': source
        })

    # API ì œí•œ ë°©ì§€ (60 RPM)
    time.sleep(1)

# ìµœì¢… ê²°ê³¼
print("\n" + "=" * 80)
print("ìµœì¢… ê²°ê³¼")
print("=" * 80)

print(f"\nâœ… ì„±ê³µ: {update_count}ê°œ")
print(f"âŒ ì‹¤íŒ¨: {len(failed)}ê°œ")

if failed:
    print(f"\nâš ï¸  ë‚ ì§œ ëª» ì°¾ì€ ê¸°ì—… ({len(failed)}ê°œ):")
    for item in failed[:10]:
        print(f"  - {item['company']}: {item['reason']}")
    if len(failed) > 10:
        print(f"  ... ì™¸ {len(failed)-10}ê°œ")

# ë‰´ìŠ¤ ê²Œì¬ì¼ ë¶„í¬
deals_updated = supabase.table("deals").select("news_date").execute()
from collections import Counter
date_counter = Counter([d['news_date'] for d in deals_updated.data if d.get('news_date')])

print(f"\nğŸ“Š ë‰´ìŠ¤ ê²Œì¬ì¼ ë¶„í¬ (ìƒìœ„ 10ê°œ):")
for date, count in sorted(date_counter.items(), reverse=True)[:10]:
    print(f"  {date}: {count}ê°œ")

# ê²°ê³¼ ì €ì¥
result_file = f"data/gemini_date_extraction_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
with open(result_file, 'w', encoding='utf-8') as f:
    json.dump({
        'total': len(deals.data),
        'success': update_count,
        'failed': failed,
        'timestamp': datetime.now().isoformat()
    }, f, ensure_ascii=False, indent=2)

print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {result_file}")
