#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì£¼ìš” VC í¬íŠ¸í´ë¦¬ì˜¤ì—ì„œ ëª» ì°¾ì€ 13ê°œ ê¸°ì—… ê²€ìƒ‰
"""

import os
import sys
import requests
from bs4 import BeautifulSoup
from datetime import datetime
from dotenv import load_dotenv
from supabase import create_client, Client
import time

# UTF-8 ì¶œë ¥ ì„¤ì •
if sys.platform == 'win32':
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')

load_dotenv()

supabase: Client = create_client(
    os.getenv("SUPABASE_URL"),
    os.getenv("SUPABASE_SERVICE_KEY")
)

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
}

# ëª» ì°¾ì€ 13ê°œ ê¸°ì—…ê³¼ íˆ¬ìì
missing_companies = {
    "ì• í”Œì—ì´ì•„ì´": "ê´‘ë¦¼ë²¤ì²˜ìŠ¤",
    "ë””ì—”í‹°í…Œí¬ì†”ë£¨ì…˜": "í‹°ì§„ì¸ë² ìŠ¤íŠ¸ë¨¼íŠ¸",
    "ì—˜ë¦¬ì‚¬ì  ": "ë°ì¼ë¦¬íŒŒíŠ¸ë„ˆìŠ¤",
    "ì˜¤í”ˆì›¨ë”©": "ì›”ë“œí”Œë¡œë¼",
    "ìŠ¤íŠœë””ì˜¤ì—í”¼ì†Œë“œ": "ìºë¦¬ì†Œí”„íŠ¸",
    "ë¶€ìŠ¤í‹°ìŠ¤": "SBIì¸ë² ìŠ¤íŠ¸ë¨¼íŠ¸",
    "íˆ¬ëª¨ë¡œìš°": "SJíˆ¬ìíŒŒíŠ¸ë„ˆìŠ¤",
    "ë¹„ë°”íŠ¸ë¡œë¡œë³´í‹±ìŠ¤": "ì¹´ì´ìŠ¤íŠ¸í™€ë”©ìŠ¤",
    "ë±ì‚¬ìŠ¤íŠœë””ì˜¤": "NCì†Œí”„íŠ¸",
    "í•œì–‘ë¡œë³´í‹±ìŠ¤": "ë‚˜ìš°ë¡œë³´í‹±ìŠ¤",
    "ì†Œì…œë¦­ìŠ¤ì½”ë¦¬ì•„": "ë„¤ì´ë²„",
    "ìŠ¤ì¹´ì´ì¸í…”ë¦¬ì „ìŠ¤": "SKAIì›”ë“œì™€ì´ë“œ",
    "í•˜ì´íŒŒì´ë¸Œë©": "DSRV"
}

# ì£¼ìš” VC í¬íŠ¸í´ë¦¬ì˜¤ URL
VC_PORTFOLIOS = {
    "ì•Œí† ìŠ¤ë²¤ì²˜ìŠ¤": "https://www.altos.vc/portfolio",
    "ë¸”ë£¨í¬ì¸íŠ¸íŒŒíŠ¸ë„ˆìŠ¤": "https://bluepoint.vc/portfolio",
    "ìŠ¤í†¤ë¸Œë¦¿ì§€ë²¤ì²˜ìŠ¤": "https://www.stonebridge.vc/portfolio",
    "KBì¸ë² ìŠ¤íŠ¸ë¨¼íŠ¸": "https://www.kbi.co.kr/portfolio",
    "ë³¸ì—”ì ¤ìŠ¤": "https://www.bonangels.net/portfolio",
}


def search_google_for_vc_portfolio(company_name, vc_name):
    """êµ¬ê¸€ ê²€ìƒ‰ìœ¼ë¡œ VC í¬íŠ¸í´ë¦¬ì˜¤ í˜ì´ì§€ ì°¾ê¸°"""

    query = f"{company_name} {vc_name} íˆ¬ì í¬íŠ¸í´ë¦¬ì˜¤"

    # Google Custom Search API ì‚¬ìš© (ìˆë‹¤ë©´)
    # ë˜ëŠ” ê°„ë‹¨í•˜ê²Œ DuckDuckGo HTML ê²€ìƒ‰

    search_url = f"https://html.duckduckgo.com/html/?q={query}"

    try:
        response = requests.get(search_url, headers=HEADERS, timeout=10)
        soup = BeautifulSoup(response.content, 'html.parser')

        # DuckDuckGo ê²€ìƒ‰ ê²°ê³¼ ë§í¬
        results = soup.find_all('a', class_='result__a')

        for result in results[:5]:  # ìƒìœ„ 5ê°œë§Œ
            href = result.get('href', '')
            title = result.get_text().strip()

            # íˆ¬ì ê´€ë ¨ í‚¤ì›Œë“œ í™•ì¸
            if any(kw in title for kw in ['íˆ¬ì', 'ìœ ì¹˜', 'í€ë”©', 'portfolio']):
                # thevc, ë‰´ìŠ¤ ì‚¬ì´íŠ¸ ë§í¬ë§Œ
                if any(domain in href for domain in ['thevc.kr', 'venturesquare', 'platum', 'wowtale', 'outstanding']):
                    return {
                        'url': href,
                        'title': title
                    }

        return None

    except Exception as e:
        return None


def main():
    print("=" * 80)
    print("VC í¬íŠ¸í´ë¦¬ì˜¤ì—ì„œ ëª» ì°¾ì€ 13ê°œ ê¸°ì—… ê²€ìƒ‰")
    print("=" * 80)

    found = 0
    not_found = []

    for idx, (company, vc) in enumerate(missing_companies.items(), 1):
        print(f"\n[{idx:2d}/13] {company:25s} (íˆ¬ì: {vc})")

        # êµ¬ê¸€ ê²€ìƒ‰ìœ¼ë¡œ VC í¬íŠ¸í´ë¦¬ì˜¤ ì°¾ê¸°
        result = search_google_for_vc_portfolio(company, vc)

        if result:
            print(f"  âœ… ë°œê²¬: {result['title'][:50]}...")
            print(f"  ğŸ”— {result['url']}")

            # DBì— ì €ì¥ ì‹œë„
            article = {
                'site_number': 99,
                'site_name': 'VC í¬íŠ¸í´ë¦¬ì˜¤',
                'site_url': "",
                'article_title': result['title'],
                'article_url': result['url'],
                'published_date': datetime.now().strftime('%Y-%m-%d')
            }

            # ì¤‘ë³µ í™•ì¸
            existing = supabase.table("investment_news_articles")\
                .select("id")\
                .eq("article_url", article['article_url'])\
                .execute()

            if not existing.data:
                try:
                    supabase.table("investment_news_articles").insert(article).execute()
                    print(f"  ğŸ’¾ DB ì €ì¥ ì™„ë£Œ")
                    found += 1
                except:
                    print(f"  âŒ DB ì €ì¥ ì‹¤íŒ¨")
            else:
                print(f"  âš ï¸  ì´ë¯¸ DBì— ìˆìŒ")
        else:
            print(f"  âŒ ëª» ì°¾ìŒ")
            not_found.append(company)

        time.sleep(2)  # ê²€ìƒ‰ ê°„ê²©

    print(f"\n{'='*80}")
    print("VC í¬íŠ¸í´ë¦¬ì˜¤ ê²€ìƒ‰ ì™„ë£Œ")
    print(f"{'='*80}")
    print(f"âœ… ë°œê²¬: {found}ê°œ")
    print(f"âŒ ëª» ì°¾ìŒ: {len(not_found)}ê°œ")

    if not_found:
        print(f"\nâŒ VC í¬íŠ¸í´ë¦¬ì˜¤ì—ì„œë„ ëª» ì°¾ì€ ê¸°ì—…:")
        for company in not_found:
            print(f"  - {company}")


if __name__ == '__main__':
    main()
