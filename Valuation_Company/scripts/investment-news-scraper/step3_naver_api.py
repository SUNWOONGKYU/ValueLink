#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
STEP 3: ë„¤ì´ë²„ APIë¡œ íˆ¬ì ë‰´ìŠ¤ ìˆ˜ì§‘
"""

import os
import sys
import csv
import requests
from datetime import datetime
from dotenv import load_dotenv
from supabase import create_client, Client
import time

# UTF-8 ì¶œë ¥ ì„¤ì •
if sys.platform == 'win32':
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')

load_dotenv()

supabase: Client = create_client(
    os.getenv("SUPABASE_URL"),
    os.getenv("SUPABASE_SERVICE_KEY")
)

NAVER_CLIENT_ID = os.getenv("NAVER_CLIENT_ID")
NAVER_CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET")


def search_naver_news(company_name, stage):
    """ë„¤ì´ë²„ APIë¡œ ë‰´ìŠ¤ ê²€ìƒ‰"""

    query = f"{company_name} {stage} íˆ¬ì ìœ ì¹˜"
    url = "https://openapi.naver.com/v1/search/news.json"

    headers = {
        'X-Naver-Client-Id': NAVER_CLIENT_ID,
        'X-Naver-Client-Secret': NAVER_CLIENT_SECRET
    }

    params = {
        'query': query,
        'display': 10,  # ìµœëŒ€ 10ê°œ
        'sort': 'date'  # ìµœì‹ ìˆœ
    }

    try:
        response = requests.get(url, headers=headers, params=params, timeout=10)

        if response.status_code == 200:
            items = response.json().get('items', [])

            # íˆ¬ì ê´€ë ¨ í‚¤ì›Œë“œ í•„í„°ë§
            investment_keywords = ['íˆ¬ì', 'ìœ ì¹˜', 'í€ë”©', 'ì‹œë¦¬ì¦ˆ', 'Series', 'ë¼ìš´ë“œ']

            for item in items:
                title = item.get('title', '').replace('<b>', '').replace('</b>', '')
                link = item.get('originallink') or item.get('link')
                pub_date = item.get('pubDate', '')

                # ê¸°ì—…ëª… í™•ì¸
                if company_name not in title:
                    continue

                # íˆ¬ì í‚¤ì›Œë“œ í™•ì¸
                if not any(kw in title for kw in investment_keywords):
                    continue

                # ë‚ ì§œ íŒŒì‹±: "Tue, 27 Jan 2026 14:30:00 +0900" â†’ "2026-01-27"
                try:
                    dt = datetime.strptime(pub_date, '%a, %d %b %Y %H:%M:%S %z')
                    published_date = dt.strftime('%Y-%m-%d')
                except:
                    published_date = datetime.now().strftime('%Y-%m-%d')

                # ì‚¬ì´íŠ¸ëª… ì¶”ì¶œ
                site_name = "ë„¤ì´ë²„ ë‰´ìŠ¤"
                if 'venturesquare.net' in link:
                    site_name = "ë²¤ì²˜ìŠ¤í€˜ì–´"
                    site_number = 9
                elif 'wowtale.net' in link:
                    site_name = "WOWTALE"
                    site_number = 1
                elif 'platum.kr' in link:
                    site_name = "í”Œë˜í…€"
                    site_number = 10
                elif 'outstanding.kr' in link:
                    site_name = "ì•„ì›ƒìŠ¤íƒ ë”©"
                    site_number = 13
                elif 'startuptoday.kr' in link:
                    site_name = "ìŠ¤íƒ€íŠ¸ì—…íˆ¬ë°ì´"
                    site_number = 11
                elif 'thebell.co.kr' in link:
                    site_name = "ë”ë²¨"
                    site_number = 16
                else:
                    site_number = 99

                return {
                    'site_number': site_number,
                    'site_name': site_name,
                    'site_url': "",
                    'article_title': title,
                    'article_url': link,
                    'published_date': published_date
                }

            return None

        else:
            return None

    except Exception as e:
        return None


def main():
    print("=" * 60)
    print("STEP 3: ë„¤ì´ë²„ APIë¡œ íˆ¬ì ë‰´ìŠ¤ ìˆ˜ì§‘")
    print("=" * 60)

    csv_file = 'sensible_companies_2026_01_COMPLETE.csv'

    # CSV ì½ê¸°
    with open(csv_file, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        companies = list(reader)

    print(f"\nì´ {len(companies)}ê°œ ê¸°ì—…")

    # ì´ë¯¸ ìˆ˜ì§‘ëœ ê¸°ì—… í™•ì¸
    result = supabase.table("investment_news_articles")\
        .select("article_title")\
        .execute()

    collected_companies = set()
    for article in result.data:
        for row in companies:
            if row['ê¸°ì—…ëª…'] in article['article_title']:
                collected_companies.add(row['ê¸°ì—…ëª…'])

    # ë¯¸ìˆ˜ì§‘ ê¸°ì—…ë§Œ í•„í„°ë§
    todo_companies = [c for c in companies if c['ê¸°ì—…ëª…'] not in collected_companies]

    print(f"ì´ë¯¸ ìˆ˜ì§‘: {len(collected_companies)}ê°œ")
    print(f"ê²€ìƒ‰ ëŒ€ìƒ: {len(todo_companies)}ê°œ\n")

    found_count = 0
    not_found = []

    for idx, row in enumerate(todo_companies, 1):
        company_name = row['ê¸°ì—…ëª…']
        stage = row['ë‹¨ê³„']

        print(f"[{idx}/{len(todo_companies)}] {company_name}...", end=' ')

        # ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰
        article = search_naver_news(company_name, stage)

        if article and article['article_url']:
            # ì¤‘ë³µ í™•ì¸
            existing = supabase.table("investment_news_articles")\
                .select("id")\
                .eq("article_url", article['article_url'])\
                .execute()

            if not existing.data:
                # DB ì €ì¥
                try:
                    supabase.table("investment_news_articles").insert(article).execute()
                    print(f"âœ… [{article['site_name']}]")
                    found_count += 1

                except Exception as e:
                    print(f"âŒ DB ì €ì¥ ì‹¤íŒ¨")
            else:
                print(f"âš ï¸ ì¤‘ë³µ")
        else:
            print("âŒ ëª» ì°¾ìŒ")
            not_found.append(company_name)

        time.sleep(0.1)  # API í˜¸ì¶œ ê°„ê²©

    print(f"\n{'='*60}")
    print("STEP 3 ì™„ë£Œ")
    print(f"{'='*60}")
    print(f"âœ… ë°œê²¬: {found_count}ê°œ")
    print(f"âŒ ë¯¸ë°œê²¬: {len(not_found)}ê°œ")
    print(f"{'='*60}")

    # ìµœì¢… í†µê³„
    result = supabase.table("investment_news_articles")\
        .select("id", count="exact")\
        .execute()

    print(f"\nğŸ“Š íˆ¬ì ë‰´ìŠ¤ í…Œì´ë¸” ì´ ë ˆì½”ë“œ: {result.count}ê°œ")

    # ë¯¸ë°œê²¬ ëª©ë¡ ì €ì¥
    if not_found:
        with open('final_not_found.txt', 'w', encoding='utf-8') as f:
            for company in not_found:
                f.write(f"{company}\n")

        print(f"\nâš ï¸ ìµœì¢… ë¯¸ë°œê²¬ ëª©ë¡ ì €ì¥: final_not_found.txt")
        print(f"   ì´ {len(not_found)}ê°œ ê¸°ì—…")


if __name__ == '__main__':
    main()
